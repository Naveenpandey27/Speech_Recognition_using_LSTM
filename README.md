# Speech_Recognition_using_LSTM
Speech recognition using LSTM is a project that involves using deep learning techniques to train a neural network to recognize and transcribe spoken words. Specifically, Long Short-Term Memory (LSTM) is a type of recurrent neural network that is well-suited for sequence processing tasks such as speech recognition.

## About Dataset 
The dataset used in this project is the TESS Toronto Emotional Speech Set data. It consists of 2800 audio files, each of duration 3 seconds, with seven different emotions: angry, disgust, fear, happy, neutral, ps, and sad. The dataset can be downloaded from the below link.

## Dataset link - https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess

## Streamlit WeBApp


![speech_again](https://user-images.githubusercontent.com/66298494/233813632-0c9f6551-7077-48c9-95f1-ff963db29162.png)


## Dependencies
This project requires the following libraries to be installed:

os
numpy
pandas
seaborn
librosa
matplotlib
IPython
keras
scikit-learn


## Usage

Step 1 - Clone the repository
Step 2 - Download the dataset and extract the zip file into the project directory.
Step 3 - Open Speech Recognition LSTM.ipynb in Jupyter Notebook or any other compatible software.
Step 4 - Run the notebook cell by cell to perform data exploration, feature extraction, model training, and testing.
Step 5 - The pretrained model is saved as speech_recognition_model.h5, which can be loaded and used for predictions.
